{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this script we split the data into the training and test set, impute missing values and save the processed data frame back to the folder - `processed-final`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer, StandardScaler\n",
    "from sklearn.base import TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class DataFrameImputer(TransformerMixin):\n",
    "    def __init__(self):\n",
    "        \"\"\"*Impute missing values*.\n",
    "\n",
    "        Columns of dtype object are imputed with the most frequent value\n",
    "        in column.\n",
    "\n",
    "        Columns of other types are imputed with mean of column.\n",
    "\n",
    "        \"\"\"\n",
    "    def fit(self, X, y=None):\n",
    "\n",
    "        self.fill = pd.Series([X[c].value_counts().index[0]\n",
    "            if X[c].dtype == np.dtype('O') else X[c].mean() for c in X],\n",
    "            index=X.columns)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X.fillna(self.fill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def split_and_impute(course_df):\n",
    "    labels = course_df['engaged']\n",
    "    features = course_df.drop(['index', 'engaged'], axis=1)\n",
    "    \n",
    "    features_train, features_test, labels_train, labels_test = train_test_split(features, labels,\n",
    "                                                                                test_size=0.2,\n",
    "                                                                                random_state=20130810) \n",
    "    \n",
    "    imputer = DataFrameImputer()\n",
    "    \n",
    "    imputer.fit(features_train)\n",
    "    \n",
    "    return imputer.transform(features_train), imputer.transform(features_test), labels_train, labels_test\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now use the scaffolding above to read in and write back the split and imputed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Global variables\n",
    "DATA_DIR = 'processed/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing HarvardXCB22x2013_Spring.feather...\n",
      "Processing HarvardXCS50x2012.feather...\n",
      "Processing HarvardXER22x2013_Spring.feather...\n",
      "Processing HarvardXPH207x2012_Fall.feather...\n",
      "Processing HarvardXPH278x2013_Spring.feather...\n",
      "Processing MITx14.73x2013_Spring.feather...\n",
      "Processing MITx2.01x2013_Spring.feather...\n",
      "Processing MITx3.091x2012_Fall.feather...\n",
      "Processing MITx3.091x2013_Spring.feather...\n",
      "Processing MITx6.002x2012_Fall.feather...\n",
      "Processing MITx6.002x2013_Spring.feather...\n",
      "Processing MITx6.00x2012_Fall.feather...\n",
      "Processing MITx6.00x2013_Spring.feather...\n",
      "Processing MITx7.00x2013_Spring.feather...\n",
      "Processing MITx8.02x2013_Spring.feather...\n",
      "Processing MITx8.MReV2013_Summer.feather...\n"
     ]
    }
   ],
   "source": [
    "for data_file in os.listdir(DATA_DIR):\n",
    "    course_df = pd.read_feather(os.path.join(DATA_DIR, data_file))\n",
    "                                \n",
    "    print('Processing {}...'.format(data_file))\n",
    "    \n",
    "    features_train, features_test, labels_train, labels_test = split_and_impute(course_df)\n",
    "    \n",
    "    course_name = data_file[:-8]\n",
    "    output_dir = os.path.join(DATA_DIR, course_name)\n",
    "    \n",
    "    if not os.path.exists(output_dir):\n",
    "        os.mkdir(output_dir)\n",
    "        \n",
    "    features_train.reset_index().to_feather(os.path.join(output_dir, 'features_train.feather'))\n",
    "    features_test.reset_index().to_feather(os.path.join(output_dir, 'features_test.feather'))\n",
    "    labels_train.reset_index().to_feather(os.path.join(output_dir, 'labels_train.feather'))\n",
    "    labels_test.reset_index().to_feather(os.path.join(output_dir, 'labels_test.feather'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
